{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d575d9e1",
   "metadata": {},
   "source": [
    "## Step:1 Dataset Description and Objective:\n",
    "\n",
    "**Dataset Description:**\n",
    "\n",
    "The dataset for this project comprises two files, namely \"customer_ratings.txt\" and \"movie_titles.csv\" each providing essential information for building a recommendation engine.\n",
    "\n",
    "`customer_ratings.txt:`\n",
    "\n",
    "* ID: Unique identifiers for customers and movies.\n",
    "* Rating: User ratings for movies.\n",
    "* Year: The year when the movie was released.\n",
    "\n",
    "`movie_titles.csv:`\n",
    "\n",
    "* Movie ID: Unique keys to identify movies.\n",
    "* Year: The year when the movie was released.\n",
    "* Movie Name: Titles of movies corresponding to their IDs.\n",
    "\n",
    "**Objective of the Project:**\n",
    "\n",
    "The aim of this project is to develop a recommendation engine for an Over-The-Top (OTT) platform or streaming service. The specific objectives are:\n",
    "\n",
    "* Create Personalized Recommendation Model: Develop a model suggesting best-suited movies for users based on their preferences and past ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e5d75",
   "metadata": {},
   "source": [
    "## Step:2 Import Necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Surprise for recommendation system\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Installing scikit-surprise library\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce63a8",
   "metadata": {},
   "source": [
    "## Step:3 Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b617e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"E:\\DS & ML Syllabus\\DS and ML projects intellipat\\netflix by harsh\\customer_ratings.txt\", \n",
    "                   header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0eb6b6",
   "metadata": {},
   "source": [
    "## Step:4 Exploratory Data Analysis (EDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9681df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa3c84",
   "metadata": {},
   "source": [
    "* Here, the data is stored differently.\n",
    "* For example, if you look at row number 0:\n",
    "    * \"1:\" represents the movie ID with no rating, so by default, NaN appears. Below this row,\n",
    "    * There are numerous customer IDs with corresponding ratings present for movie number \"1.\"\n",
    "* Similarly, data is stored for movie IDs \"2:\", \"3:\", and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 5 rows\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4fd78b",
   "metadata": {},
   "source": [
    "* In this dataset, we have more than 24 million entries, and the data is stored in its raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps to understand the data type and information about data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the total number of movies, \n",
    "# we can simply count the number of null values in the rating column. \n",
    "# Null values in the rating column correspond to movie IDs stored in the customer_id column. \n",
    "# By counting these null values, we can determine the total number of movies in the dataframe.\n",
    "movie_count = data.isna().sum()\n",
    "movie_count = movie_count['Rating']\n",
    "movie_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7f881",
   "metadata": {},
   "source": [
    "* So, the total number of movies in this dataset is 4499."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac70e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the count of unique customers we have in this dataset.\n",
    "customer_count = data['Cust_Id'].nunique()\n",
    "customer_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d880ef3",
   "metadata": {},
   "source": [
    "* Here, 475257 represents the total number of entries where both uinque customer_id and unique movie_id are stored together. \n",
    "* To obtain only customer_id, we need to exclude movie_id from this count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88844f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we are removing movie_id from this count\n",
    "customer_count = customer_count - movie_count\n",
    "customer_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9c9ec",
   "metadata": {},
   "source": [
    "* So total no of unique customers = 470758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the total number of ratings provided by customers.\n",
    "rating_count = data['Cust_Id'].count()-movie_count\n",
    "rating_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d322ca",
   "metadata": {},
   "source": [
    "* We already know that we have 4,999 movies, and a customer can watch any movie multiple times. However, each customer's rating for a movie is stored only once and updated if they change their rating. We have calculated that 470,758 customers have given a total of 24,053,764 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find out how many people have rated the movies as 1*, 2*, 3*,4*, 5* stars ratings to the movies\n",
    "stars = data.groupby('Rating')['Rating'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fecb1",
   "metadata": {},
   "source": [
    "* 1118186 people rated movies as 1*\n",
    "* 2439073 people rated movies as 2*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6055e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot showing the distribution of ratings\n",
    "ax = stars.plot(kind='barh', legend=False, figsize=(10,5))\n",
    "plt.title(f'Total pool: {movie_count} Movies, {customer_count} Customers, {rating_count} ratings given', fontsize=14, loc='left')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd89e4",
   "metadata": {},
   "source": [
    "### 4.1 Feature Engineering:\n",
    "* Creating relevant features from existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba830b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding another column in the dataset named 'movie id'.\n",
    "# First, we'll calculate how many null values we have in the ratings column because i.e nothing \n",
    "# but total no of movies we have in the dataset.\n",
    "df_nan = pd.DataFrame(data['Rating'].isnull())\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data, for getting rows where Movie_Id is present\n",
    "df_nan = df_nan[df_nan['Rating']==True]\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e42056",
   "metadata": {},
   "source": [
    "* From the above, I can say that movie1 is stored from index 0 to 547.\n",
    "* How did we get this?\n",
    "* The number of customers who rated movie1 is 548−0−1 (the -1 is because from index 548 onwards, another movie is stored).\n",
    "* The number of customers who rated movie2 is 694−548−1 (the -1 is because from index 694 onwards, another movie is stored).\n",
    "* Similarly, for other movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will reset the index as the column\n",
    "df_nan = df_nan.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc15fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just understand \n",
    "x=zip(df_nan['index'][1:], df_nan['index'][:-1])\n",
    "tuple(x)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a numpy array containing movie id's according to the 'ratings' dataset\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # Numpy approach: \n",
    "    # Fill 1 in rows from 0 to 547. \n",
    "    temp = np.full((1,i-j-1), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "    \n",
    "# Account \"\"for last record\"\" and corresponding length\n",
    "# Numpy approach\n",
    "last_record = np.full((1,len(data) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "print(f'Movie numpy: {movie_np}')\n",
    "print(f'Length: {len(movie_np)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typecasting and adding Movie_Id column in dataset\n",
    "data=data[pd.notnull(data['Rating'])]\n",
    "data['Movie_Id']=movie_np.astype(int)\n",
    "data['Cust_Id']=data['Cust_Id'].astype(int)\n",
    "print(\"Now the dataset will look like: \")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8643b",
   "metadata": {},
   "source": [
    "### 4.2 Data cleaning and Adding BenchMark:\n",
    "\n",
    "In this step, our focus is on refining the dataset to meet specific criteria for analysis efficiency and reliability.\n",
    "\n",
    "Establishing a benchmark involves setting minimum standards for dataset inclusion. This is vital to optimize our resources and ensure our analysis is grounded in meaningful data.\n",
    "\n",
    "The benchmark criteria include:\n",
    "\n",
    "* `Filtering Users`: We exclude users who have rated only a small number of movies. This step helps mitigate the influence of potential fake ratings, often used by media companies to artificially boost ratings.\n",
    "\n",
    "* `Filtering Movies`: Similarly, we exclude movies with only a few ratings, even if they have high average ratings. For example, a movie like movieID = 65, despite receiving a high average rating (such as 5 stars), may not provide sufficient data for robust analysis if it's rated by only a handful of individuals.\n",
    "\n",
    "Implementing these benchmarks aims to ensure our recommendation engine relies on a more substantial and reliable dataset. This approach enhances recommendation accuracy by leveraging diverse and representative data, ultimately improving the overall user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8261f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list where we store aggregation var name\n",
    "f = ['count','mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data a/c to movie_id\n",
    "dataset_movie_summary = data.groupby('Movie_Id').agg(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f76cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing grouped data\n",
    "dataset_movie_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626c503",
   "metadata": {},
   "source": [
    "* so if you see above `cust_id` and `their mean` isn't making any sense so we are not taking this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we are taking only 'Rating' and 'movie_id column and Grouped by \"Movie_id\" column\n",
    "dataset_movie_summary = data.groupby('Movie_Id')['Rating'].agg(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now viewing it\n",
    "dataset_movie_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am considering only that movie in our data, which is rated by almost 70% of people\n",
    "dataset_movie_summary[\"count\"].quantile(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d43b6f",
   "metadata": {},
   "source": [
    "* I am considering only that movie which is rated by almost 1800  people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622895e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a benchmark\n",
    "# By considering only that movie which is rated by almost 1800 people\n",
    "movie_benchmark=round(dataset_movie_summary['count'].quantile(0.7),0)\n",
    "movie_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7306f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_movie_summary['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4763c",
   "metadata": {},
   "source": [
    "* so now what we are going to do is, we are removing movies which is not rated by 1799 people\n",
    "* like we are removing movie id 1,2,4,5,4495,4497,4498 like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering movies which is less than 1799 ratings\n",
    "drop_movie_list = dataset_movie_summary[dataset_movie_summary['count']<movie_benchmark].index\n",
    "drop_movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we'll filter out users who are inactive, meaning they haven't been active frequently\n",
    "dataset_cust_summary=data.groupby('Cust_Id')['Rating'].agg(f)\n",
    "dataset_cust_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80730254",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_benchmark=round(dataset_cust_summary['count'].quantile(0.7),0)\n",
    "cust_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43705b2",
   "metadata": {},
   "source": [
    "* I am only considering that users who have rated atleast 52 movies\n",
    "* so below we are going to drop users who have not rated 52 movies atleast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc167e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Customers Who Have Rated Fewer Than 52 Movies.\n",
    "drop_cust_list=dataset_cust_summary[dataset_cust_summary['count']<cust_benchmark].index\n",
    "drop_cust_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just checking original dataframe size\n",
    "# So further we will observe changes because we will remove all the customers and movies that are below the benchmark\n",
    "print('The original dataframe has: ', data.shape, 'shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ae176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are removing customers and movies which are below the benchmark.\n",
    "data = data[~data['Movie_Id'].isin(drop_movie_list)]\n",
    "data = data[~data['Cust_Id'].isin(drop_cust_list)]\n",
    "print('After the triming, the shape is: {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8e87a",
   "metadata": {},
   "source": [
    "### 4.3 Integrating 'movie_title' Column from Another DataFrame into the Current DataFrame:\n",
    "\n",
    "* In this step, we merge data from another dataframe to enrich our movie information.\n",
    "\n",
    "Since directly recommending movies based on their IDs may not provide meaningful insights to users, we opt to enhance our dataset by incorporating a file containing the title names of movies. This allows for a more user-friendly presentation of movie recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a12a32",
   "metadata": {},
   "source": [
    "Our movie title data is initially in text format. To ensure compatibility with our current DataFrame and to avoid Unicode format errors during conversion to CSV, we've converted the data to CSV format. It's important to note that due to the text format's nature, encoding is required for proper functioning. Without encoding, attempting to convert the data directly into CSV format may result in Unicode format errors. Therefore, encoding is essential for seamless integration of the movie title information into our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "df_title = pd.read_csv(r\"E:\\DS & ML Syllabus\\DS and ML projects intellipat\\netflix by harsh\\movie_titles.csv\",  encoding='ISO-8859-1', header=None, usecols=[0,1,2], names=['Movie_Id','Year','Name' ])\n",
    "df_title.set_index('Movie_Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing new dataset\n",
    "df_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208abfe",
   "metadata": {},
   "source": [
    "## 5 Data visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of Movies Released per Year\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_title['Year'], bins=20)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Movies Released per Year');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab073e",
   "metadata": {},
   "source": [
    "* From the above plot, we can clearly see that as the years increase, the number of movies released also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b61f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Movies Released per decade\n",
    "plt.figure(figsize=(10, 5))\n",
    "(df_title['Year'] // 10 * 10).value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Decade')\n",
    "plt.ylabel('Number of Movies Released')\n",
    "plt.title('Number of Movies Released per decade');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fb275",
   "metadata": {},
   "source": [
    "* The plot shows a significant increase in the number of movies released after 1980, likely due to the advent of cheaper televisions and improved electricity supply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ac50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Movie Rating Over Time\n",
    "\n",
    "merged_data = data.merge(df_title, on=\"Movie_Id\")\n",
    "\n",
    "# Calculate average rating per year\n",
    "average_ratings = merged_data.groupby(\"Year\")[\"Rating\"].mean()\n",
    "\n",
    "# Create line plot\n",
    "plt.figure(figsize=(10, 5))  # Adjust figure size as desired\n",
    "plt.plot(average_ratings.index, average_ratings.values)\n",
    "plt.xlabel(\"Release Year\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.title(\"Average Movie Rating Over Time\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee22297",
   "metadata": {},
   "source": [
    "* If you observe this plot, you can see that from 1940 to 1970, there are consistently high ratings from customers. This may be because this period saw the release of many high-quality movies, and movies were still a relatively new form of entertainment for people during this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4af9fe",
   "metadata": {},
   "source": [
    "## Step: 6 Implementing a Netflix Recommendation Engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scikit-surprise package is a Python library for building and analyzing recommender systems. \n",
    "# To install this use \"conda install -c conda-forge scikit-surprise\" or \n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6077ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "import math\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Reader class to read the dataset for the SVD algorithm\n",
    "reader=Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DatasetAutoFolds object to DataFrame\n",
    "# Create a DataFrame from the dataset with columns: 'Cust_Id', 'Movie_Id', 'Rating'\n",
    "df = pd.DataFrame(data, columns=['Cust_Id', 'Movie_Id', 'Rating'])\n",
    "\n",
    "# We only work with the top 100K rows for quicker runtime, as even 12GB of RAM in Google Colab may not be sufficient\n",
    "# Select the top 100K rows from the DataFrame\n",
    "df_subset = df[['Cust_Id', 'Movie_Id', 'Rating']][:100000]\n",
    "\n",
    "# Load the data into a Surprise dataset\n",
    "# Load the DataFrame subset into a Surprise dataset using the previously defined 'reader'\n",
    "dataset = Dataset.load_from_df(df_subset, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVD algorithm\n",
    "# Create an instance of the SVD algorithm for collaborative filtering\n",
    "svd = SVD()\n",
    "\n",
    "# Perform cross-validation on the dataset\n",
    "# Evaluate the SVD algorithm using cross-validation with measures of RMSE and MAE\n",
    "# Print verbose output to show progress\n",
    "cross_validate(svd, dataset, measures=['RMSE', 'MAE'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594970df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab5f8f",
   "metadata": {},
   "source": [
    "### 6.1 Predicting Movies for 'cust_id 712664':\n",
    "* Apply machine learning techniques to predict movies for a specific customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858826c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So first, we select user 712664 and attempt to recommend some movies based on their past data.\n",
    "# Since the user has rated many movies with 5 stars, we'll use those ratings as a reference.\n",
    "# This will help us understand the type of movies they like to watch.\n",
    "\n",
    "# Filter the dataset to include only movies rated 5 stars by user 712664\n",
    "dataset_712664 = data[(data['Cust_Id'] == 712664) & (data['Rating'] == 5)]\n",
    "dataset_712664 = dataset_712664.set_index('Movie_Id')\n",
    "dataset_712664 = dataset_712664.join(df_title)['Name']\n",
    "\n",
    "# Display the filtered dataset\n",
    "dataset_712664"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedbddd",
   "metadata": {},
   "source": [
    "* So from the filtered dataset above, we can see the movies that user 712664 rated with 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will build the recommendation algorithm.\n",
    "# First, we will make a shallow copy of the 'movie_titles.csv' file so that we can modify\n",
    "# the values in the copied dataset, not in the actual dataset.\n",
    "\n",
    "# Create a shallow copy of the 'movie_titles.csv' dataset\n",
    "user_712664 = df_title.copy()\n",
    "\n",
    "# Display the copied dataset\n",
    "user_712664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b660c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just resetting index\n",
    "user_712664 = user_712664.reset_index()\n",
    "user_712664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out movies for user_712664 based on benchmark criteria\n",
    "user_712664 = user_712664[~user_712664['Movie_Id'].isin(drop_movie_list)]\n",
    "user_712664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying estimator function on SVD decomposition for user 712664\n",
    "user_712664['Estimate_Score'] = user_712664['Movie_Id'].apply(lambda x: svd.predict(712664, x).est)\n",
    "\n",
    "# Dropping 'Movie_Id' column from the dataset\n",
    "user_712664 = user_712664.drop('Movie_Id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5721e35",
   "metadata": {},
   "source": [
    "### 6.2 Recommended Movies for Customer \"cust_id 712664\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4beddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting user_712664 dataframe based on the estimated scores in descending order\n",
    "user_712664 = user_712664.sort_values('Estimate_Score', ascending=False)\n",
    "\n",
    "# Printing the sorted dataframe\n",
    "print(user_712664)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c526820",
   "metadata": {},
   "source": [
    "* So, if you recommend these types of movies to this user, then he will likely enjoy them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160bf23",
   "metadata": {},
   "source": [
    "## Step 7 Model Saving and Loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('../models/recommendation_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "with open('../models/recommendation_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendations(user_id, data, df_title, drop_movie_list, loaded_model):\n",
    "    # Filter the dataset to include only movies rated 5 stars by the specified user\n",
    "    dataset_user = data[(data['Cust_Id'] == user_id) & (data['Rating'] == 5)]\n",
    "    dataset_user = dataset_user.set_index('Movie_Id')\n",
    "    dataset_user = dataset_user.join(df_title)['Name']\n",
    "\n",
    "    # Create a DataFrame containing all movie IDs\n",
    "    user_movies = df_title.copy()\n",
    "    user_movies = user_movies.reset_index()\n",
    "    user_movies = user_movies[~user_movies['Movie_Id'].isin(drop_movie_list)]\n",
    "\n",
    "    # Applying estimator function on SVD decomposition for the specified user\n",
    "    user_movies['Estimate_Score'] = user_movies['Movie_Id'].apply(lambda x: loaded_model.predict(user_id, x).est)\n",
    "\n",
    "    # Dropping 'Movie_Id' column from the dataset\n",
    "    user_movies = user_movies.drop('Movie_Id', axis=1)\n",
    "\n",
    "    # Sorting user_movies DataFrame based on the estimated scores in descending order\n",
    "    user_movies = user_movies.sort_values('Estimate_Score', ascending=False)\n",
    "    return user_movies\n",
    "\n",
    "# Example of how to use the function for recommendations for user 712664\n",
    "user_id = 712664\n",
    "user_recommendations = get_user_recommendations(user_id, data, df_title, drop_movie_list, loaded_model)\n",
    "print(user_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd271fc",
   "metadata": {},
   "source": [
    "* So, if you recommend these types of movies to this user, then he will likely enjoy them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb2599",
   "metadata": {},
   "source": [
    "## Step 8 Conclusion:\n",
    "\n",
    "This project aimed to develop a personalized recommendation engine for an OTT platform using user ratings and movie metadata. The dataset comprised user ratings and movie titles, and the primary goal was to recommend movies tailored to individual user preferences.\n",
    "\n",
    "### 8.1 Key Steps and Findings:\n",
    "\n",
    "\n",
    "**Data Exploration and Preprocessing:** We began with two datasets: customer_ratings.txt and movie_titles.csv, containing user ratings and movie information, respectively.\n",
    "The initial exploration revealed the structure and format of the data, including the presence of NaN values representing movie IDs.\n",
    "Through feature engineering, we created a cohesive dataset by integrating movie IDs into the customer ratings data.\n",
    "\n",
    "**Data Cleaning and Benchmarking:** We established benchmarks to filter out movies and users with insufficient ratings. Specifically, we retained only movies rated by at least 1,799 users and users who rated at least 52 movies. This ensured our analysis was based on substantial and reliable data.\n",
    "\n",
    "**Data Integration:** We merged the movie titles dataset with the ratings data, enriching our dataset with movie names and release years. This integration facilitated more meaningful recommendations by presenting movie titles instead of mere IDs.\n",
    "\n",
    "**Data Visualization:** Visualizations provided insights into the distribution of movies released per year and decade, as well as average movie ratings over time. These visualizations highlighted trends and patterns, such as the increase in movie releases over the decades and high average ratings from the 1940s to the 1970s.\n",
    "\n",
    "**Recommendation Engine Development:** Utilizing the scikit-surprise library, we implemented the Singular Value Decomposition (SVD) algorithm, a popular collaborative filtering technique for recommendation systems.\n",
    "The dataset was loaded into the SVD model, and cross-validation was performed to evaluate its performance.\n",
    "\n",
    "### 8.2 Final Thoughts:\n",
    "\n",
    "The recommendation engine built in this project leverages collaborative filtering to provide personalized movie recommendations to users based on their past ratings and preferences. By cleaning the data and setting benchmarks, we ensured that the recommendations are based on reliable and significant user interactions. This engine is a crucial step toward enhancing user experience on an OTT platform, offering tailored suggestions that align with individual user tastes.\n",
    "\n",
    "### 8.3 Future Improvements\n",
    "Future improvements could include incorporating additional features such as movie genres, user demographics, and more advanced recommendation algorithms to further refine and enhance the recommendation capabilities of the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
